import json
from typing import Callable, List, Any

from swarms import (
    GPT4VisionAPI,
    OpenAIChat,
    Conversation,
    SwarmNetwork,
    Agent,
)

from autort.prompts import (
    FILTER_TASKS_SOP_PROMPT,
    FUSED_SYSTEM_PROMPT_WITH_SOP,
    GENERATE_TASKS_PROMPT,
    VISUALIZE_OBJECT_PROMPT,
)

guidance_vllm = "Effectively visualize the object in the scene."
guidance_llm = "Generate tasks for the robot to perform."
guidance_rank = (
    "Rank the tasks generated based on complexity and necessity of"
    " human assistance."
)


class AutoRTAgent:
    """
    AutoRTSwarm class represents an automated robot task system.

    Args:
        openai_api_key (str): The API key for OpenAI.
        max_tokens (int, optional): The maximum number of tokens to use for text generation. Defaults to 1000.
        guidance_vllm (str, optional): The guidance for the first language model. Defaults to guidance_vllm.
        guidance_llm (str, optional): The guidance for the second language model. Defaults to guidance_llm.
        guidance_rank (str, optional): The guidance for the third language model. Defaults to guidance_rank.
        robot_model (Callable, optional): The robot model to execute the tasks. Defaults to None.

    Attributes:
        openai_api_key (str): The API key for OpenAI.
        max_tokens (int): The maximum number of tokens to use for text generation.
        guidance_vllm (str): The guidance for the first language model.
        guidance_llm (str): The guidance for the second language model.
        guidance_rank (str): The guidance for the third language model.
        robot_model (Callable): The robot model to execute the tasks.
        system_prompt_vllm (FUSED_SYSTEM_PROMPT_WITH_SOP): The system prompt for the first language model.
        system_prompt_llm (FUSED_SYSTEM_PROMPT_WITH_SOP): The system prompt for the second language model.
        system_prompt_rank (FUSED_SYSTEM_PROMPT_WITH_SOP): The system prompt for the third language model.
        vllm (GPT4VisionAPI): The first language model to visualize the object in the scene.
        llm (OpenAIChat): The second language model to generate tasks for the robot.
        filter_llm (OpenAIChat): The third language model to rank the tasks generated by the second language model.

    Methods:
        run(text: str, img: str, *args, **kwargs) -> Any:
            Runs the AutoRTSwarm system to execute tasks based on the given text and image.

    Examples:
        >>> from autort import AutoRTSwarm
        >>> autort = AutoRTSwarm(openai_api_key, max_tokens=1000)
        >>> autort.run("There is a bottle on the table.", "https://i.imgur.com/2qY9f8U.png")

    """

    def __init__(
        self,
        openai_api_key: str,
        max_tokens: int = 1000,
        guidance_vllm: str = guidance_vllm,
        guidance_llm: str = guidance_llm,
        guidance_rank: str = guidance_rank,
        robot_model: Callable = None,
        *args,
        **kwargs,
    ):
        super().__init__(*args, **kwargs)
        self.openai_api_key = openai_api_key
        self.max_tokens = max_tokens
        self.guidance_vllm = guidance_vllm
        self.guidance_llm = guidance_llm
        self.guidance_rank = guidance_rank
        self.robot_model = robot_model

        self.system_prompt_vllm = FUSED_SYSTEM_PROMPT_WITH_SOP(
            guidance=guidance_vllm,
            sop=VISUALIZE_OBJECT_PROMPT,
        )

        self.system_prompt_llm = FUSED_SYSTEM_PROMPT_WITH_SOP(
            guidance=guidance_llm,
            sop=GENERATE_TASKS_PROMPT,
        )

        self.system_prompt_rank = FUSED_SYSTEM_PROMPT_WITH_SOP(
            guidance_rank,
            FILTER_TASKS_SOP_PROMPT,
        )
        
        # LLM
        llm = OpenAIChat(openai_api_key=openai_api_key)
        

        # 1st LLM to visualize the object in the scene using GPT4V
        self.vllm = Agent(
            llm=llm,
            system_prompt=self.system_prompt_vllm,
        )

        # 2nd LLM to generate tasks for the robot to perform based on the objects in the scene
        self.tasks_generator = OpenAIChat(
            openai_api_key=openai_api_key,
            max_tokens=max_tokens,
            prefix_messages=[FUSED_SYSTEM_PROMPT_WITH_SOP()],
        )

        # 3rd LLM to rank the tasks generated by the 2nd LLM based on complexity and necessity of human assistance
        self.task_filter = OpenAIChat(
            openai_api_key=openai_api_key,
            max_tokens=max_tokens,
            prefix_messages=[self.system_prompt_rank],
        )

    def run(self, text: str, img: str, *args, **kwargs):
        """
        Runs the AutoRTSwarm system to execute tasks based on the given text and image.

        Args:
            text (str): The text input for the system.
            img (str): The image input for the system.
            *args: Additional positional arguments.
            **kwargs: Additional keyword arguments.

        Returns:
            Any: The result of executing the robot model on the ranked tasks.

        """
        # 1st LLM to visualize the object in the scene using GPT4V
        vllm = self.vllm.run(text, img)

        # 2nd LLM to generate tasks for the robot to perform based on the objects in the scene
        tasks = self.tasks_generator(vllm)

        # 3rd LLM to rank the tasks generated by the 2nd LLM based on complexity and necessity of human assistance
        ranks = self.task_filter(tasks)

        # Robot model to execute the tasks
        return self.robot_model(ranks, img)


class AutoRTSwarm:
    """
    Represents a swarm of AutoRTSwarmAgents.

    Args:
        agents (List[AutoRTSwarmAgent]): A list of AutoRTSwarmAgent objects.
        datastore (Any): The datastore to store the results of the agents.

    Attributes:
        agents (List[AutoRTSwarmAgent]): A list of AutoRTSwarmAgent objects.
        datastore (Any): The datastore to store the results of the agents.

    Examples:
        >>> from autort import AutoRTSwarm, AutoRTAgent
        >>> agents = [
        ...     AutoRTAgent(openai_api_key, max_tokens=1000),
        ...     AutoRTAgent(openai_api_key, max_tokens=1000),
        ... ]
        >>> autort_swarm = AutoRTSwarm(agents, datastore)
        >>> autort_swarm.run("There is a bottle on the table.", "https://i.imgur.com/2qY9f8U.png")
    """

    def __init__(
        self,
        agents: List[AutoRTAgent],
        datastore: Any = None,
        autosave: bool = True,
        *args,
        **kwargs,
    ):
        self.agents = agents
        self.datastore = datastore
        self.autosave = autosave
        self.conversation = Conversation(
            time_enabled=True,
            save_filepath="autort_conversation.json",
            *args,
            **kwargs,
        )

        # Swarm Network
        self.network = SwarmNetwork(
            agents=self.agents, logging_enabled=True, *args, **kwargs
        )

    def run(self, text: str, img: str = None, *args, **kwargs):
        """
        Runs the AutoRTSwarmAgents in the swarm.

        Args:
            text (str): The text input for the agents.
            img (str): The image input for the agents.
            *args: Additional positional arguments.
            **kwargs: Additional keyword arguments.

        Returns:
            List: A list of results from running each agent.
        """
        out = self.network.run_many_agents(text, img, *args, **kwargs)

        if self.autosave:
            self.conversation.save_to_json(
                self.conversation.save_filepath, out
            )

        return out

    def save_to_json(self, filename: str, content: List):
        # Save the conversation to a JSON file
        with open(filename, "w") as f:
            json.dump(content, f, indent=4)

    def load_from_json(self, filename: str):
        # Load the conversation from a JSON file
        with open(filename, "r") as f:
            content = json.load(f)

        return content
